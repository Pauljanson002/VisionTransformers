{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from models import model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = model_factory.create_model('vit_lite_h')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "import torch\n",
    "model.load_state_dict(torch.load('../state_dicts/vit_lite_h.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from utils import get_optimizer\n",
    "optimizer = get_optimizer('adamw',model.parameters(),0.0005,3e-2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch':100,\n",
    "    'model_state_dict':model.state_dict(),\n",
    "    'optimizer_state_dict':optimizer.state_dict(),\n",
    "    'loss':0.01\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Saved successfully\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "torch.save(checkpoint,f\"../checkpoints/vit_lite_h_100.pt\")\n",
    "print('Saved successfully')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from models import model_factory\n",
    "model = model_factory.create_model('vit_lite_seq')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ViTLiteSeq(\n",
      "  (tokenizer): Tokenizer(\n",
      "    (conv_layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 256, kernel_size=(4, 4), stride=(4, 4))\n",
      "        (1): Identity()\n",
      "        (2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (flattener): Flatten(start_dim=2, end_dim=3)\n",
      "  )\n",
      "  (classifier): Transformer(\n",
      "    (attention_pool): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (8): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (9): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (10): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (11): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (12): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (13): TransformerEncoder(\n",
      "        (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(model)\n",
    "x = torch.randn(1,3,32,32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(1,3,32,32)\n",
    "y  = model.tokenizer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 64, 256])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 22
    }
   ],
   "source": [
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "z = model.classifier.blocks[0](y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 64, 256])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ],
   "source": [
    "z.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "z = model.classifier.attention_pool(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 64, 1])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    }
   ],
   "source": [
    "z.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[[0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0157],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0155],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0158],\n",
      "         [0.0155],\n",
      "         [0.0155],\n",
      "         [0.0157],\n",
      "         [0.0157],\n",
      "         [0.0155],\n",
      "         [0.0156],\n",
      "         [0.0155],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0155],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0158],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0157],\n",
      "         [0.0158],\n",
      "         [0.0158],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0155],\n",
      "         [0.0155],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0156],\n",
      "         [0.0155],\n",
      "         [0.0157],\n",
      "         [0.0156],\n",
      "         [0.0157],\n",
      "         [0.0157]]], grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([1, 3, 32, 32])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "z = F.softmax(z,dim=1) \n",
    "print(z)\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0636,  0.1233, -0.1487,  0.0743, -0.1754,  0.0286,  0.0215, -0.0323,\n          0.0236, -0.0191]], grad_fn=<AddmmBackward>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 31
    }
   ],
   "source": [
    "model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from train_v2 import adjust_learning_rate \n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "model = model_factory.create_model('vit_lite_h')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from utils.optimizer_factory import get_optimizer\n",
    "optimizer = get_optimizer('adamw',model.parameters(),0.0005,3e-2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(len(optimizer.param_groups))\n",
    "for i in range(1,101):\n",
    "    adjust_learning_rate(optimizer,i,0.0005,100,5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.0, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.03, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359]}]}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(optimizer.state_dict())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 56
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"../state_dicts/vit_lite_h.pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "        'epoch': 100,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'accuracy':90.0 \n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "torch.save(model_dict,f\"../checkpoints/vit_lite_h_100.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}